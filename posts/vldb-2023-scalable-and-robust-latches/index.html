<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>[VLDB 2023] Scalable and Robust Latches for Database Systems | Jian Zhang</title><meta name=keywords content><meta name=description content="Introduction Efficient and scalable synchronization is one of the key require- ments for systems that run on modern multi-core processors. ä½†æ˜¯è™½ç„¶æœ‰å¾ˆå¤šç±»å‹çš„ Lockï¼Œä½†æ˜¯å´æ²¡æœ‰äººè¯¦ç»†ç ”ç©¶è¿‡ä»€ä¹ˆæ ·çš„ Lock é€‚ç”¨äºæ•°æ®åº“çš„å·¥ä½œè´Ÿè½½ï¼Œä¸»è¦åŸå› æ˜¯æ•°æ®"><meta name=author content="Jian"><link rel=canonical href=https://zz-jason.github.io/posts/vldb-2023-scalable-and-robust-latches/><link href=/assets/css/stylesheet.min.bdb03579c17662815eb277a528f9b9b67a014d2778e9fb0aa5489aa14f7b2643.css integrity="sha256-vbA1ecF2YoFesnelKPm5tnoBTSd46fsKpUiaoU97JkM=" rel="preload stylesheet" as=style><link rel=icon href=https://zz-jason.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://zz-jason.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://zz-jason.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://zz-jason.github.io/apple-touch-icon.png><link rel=mask-icon href=https://zz-jason.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.80.0"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-67872953-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="[VLDB 2023] Scalable and Robust Latches for Database Systems"><meta property="og:description" content="Introduction Efficient and scalable synchronization is one of the key require- ments for systems that run on modern multi-core processors. ä½†æ˜¯è™½ç„¶æœ‰å¾ˆå¤šç±»å‹çš„ Lockï¼Œä½†æ˜¯å´æ²¡æœ‰äººè¯¦ç»†ç ”ç©¶è¿‡ä»€ä¹ˆæ ·çš„ Lock é€‚ç”¨äºæ•°æ®åº“çš„å·¥ä½œè´Ÿè½½ï¼Œä¸»è¦åŸå› æ˜¯æ•°æ®"><meta property="og:type" content="article"><meta property="og:url" content="https://zz-jason.github.io/posts/vldb-2023-scalable-and-robust-latches/"><meta property="article:published_time" content="2023-04-05T00:00:00+00:00"><meta property="article:modified_time" content="2023-04-05T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="[VLDB 2023] Scalable and Robust Latches for Database Systems"><meta name=twitter:description content="Introduction Efficient and scalable synchronization is one of the key require- ments for systems that run on modern multi-core processors. ä½†æ˜¯è™½ç„¶æœ‰å¾ˆå¤šç±»å‹çš„ Lockï¼Œä½†æ˜¯å´æ²¡æœ‰äººè¯¦ç»†ç ”ç©¶è¿‡ä»€ä¹ˆæ ·çš„ Lock é€‚ç”¨äºæ•°æ®åº“çš„å·¥ä½œè´Ÿè½½ï¼Œä¸»è¦åŸå› æ˜¯æ•°æ®"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://zz-jason.github.io/posts/"},{"@type":"ListItem","position":2,"name":"[VLDB 2023] Scalable and Robust Latches for Database Systems","item":"https://zz-jason.github.io/posts/vldb-2023-scalable-and-robust-latches/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"[VLDB 2023] Scalable and Robust Latches for Database Systems","name":"[VLDB 2023] Scalable and Robust Latches for Database Systems","description":"Introduction Efficient and scalable synchronization is one of the key require- ments for systems that run on modern multi-core processors. ä½†æ˜¯è™½ç„¶æœ‰å¾ˆå¤šç±»å‹çš„ Lockï¼Œä½†æ˜¯å´æ²¡æœ‰äººè¯¦ç»†ç ”ç©¶è¿‡ä»€ä¹ˆæ ·çš„ Lock é€‚ç”¨äºæ•° â€¦","keywords":[],"articleBody":"Introduction Efficient and scalable synchronization is one of the key require- ments for systems that run on modern multi-core processors.\nä½†æ˜¯è™½ç„¶æœ‰å¾ˆå¤šç±»å‹çš„ Lockï¼Œä½†æ˜¯å´æ²¡æœ‰äººè¯¦ç»†ç ”ç©¶è¿‡ä»€ä¹ˆæ ·çš„ Lock é€‚ç”¨äºæ•°æ®åº“çš„å·¥ä½œè´Ÿè½½ï¼Œä¸»è¦åŸå› æ˜¯æ•°æ®åº“çš„å·¥ä½œè´Ÿè½½èŒƒå›´å¾ˆå¤§ï¼Œæœ‰ write-heavy OLTP äº‹åŠ¡ï¼Œä¹Ÿæœ‰ read-only çš„ OLAP æŸ¥è¯¢ï¼Œç”šè‡³æ˜¯ä¸¤è€…éƒ½æœ‰çš„ HTAP è´Ÿè½½ã€‚\nåœ¨è®¾è®¡ Umbra çš„æ—¶å€™ï¼Œä½œè€…å¼€å§‹è°ƒç ”ä¸åŒçš„é”æœºåˆ¶å’Œä»–ä»¬ä¹‹é—´çš„æ•ˆç‡å·®å¼‚ã€‚é¦–å…ˆç¬¬ä¸€ä¸ªå‘ç°æ˜¯ä¸å¯èƒ½æœ‰ä¸€ç§é”æœºåˆ¶åœ¨æ‰€æœ‰å·¥ä½œè´Ÿè½½å’Œæ‰€æœ‰ç¡¬ä»¶ç¯å¢ƒä¸­éƒ½æ˜¯æœ€ä¼˜çš„ã€‚How- ever, we noticed that there are some re-occurring best practices for locking and synchronizationã€‚äºæ˜¯ä½œè€…ä»¬é¦–å…ˆæ€»ç»“äº†æ•°æ®åº“åœ¨ Lock ä¸Šçš„éœ€æ±‚ï¼Œç„¶å address them by analyzing and evaluating different locking techniques accordinglyã€‚\né‚£å¯¹æ•°æ®åº“å‹å¥½çš„ Lock éœ€è¦å…·å¤‡ä»€ä¹ˆæ ·çš„åŠŸèƒ½å‘¢ï¼Ÿ\nè¯»æ˜¯éœ€è¦åˆå¿«æœ‰èƒ½ scale çš„ï¼š\n In general, most database workloads, even OLTP transac- tions, mostly read data, and thus reading should be fast and scalable.\n åœ¨ LLVM JIT çš„æƒ…å†µä¸‹ï¼Œçº¯ç²¹ä½¿ç”¨ OS æä¾›çš„ Lock ä¸å¤ªè¡Œï¼š\n Many modern in-memory database systems compile queries to efficient machine code to keep the latency as low as possible [26]. A lock should therefore integrate well with query compilation and avoid external function calls. This requirement makes pure OS- based locks unattractive for frequent usage during query execution.\n å› ä¸º Lock éœ€è¦ä¿æŠ¤ä¸€äº›ç»†ç²’åº¦çš„æ•°æ®ç»“æ„ï¼ŒLock æœ¬èº«çš„ç©ºé—´å¼€é”€åº”è¯¥å°½é‡å°ï¼š\n To protect fine-granular data like index nodes, or hash table buckets, the lock itself should be space efficient. This does not necessarily mean minimal, but it should also not waste unreasonable amount of space. For instance, a std::mutex (40-80 bytes) would almost double the size required for an ART node [17].\n Lock è¿˜éœ€è¦èƒ½å¤Ÿé«˜æ•ˆçš„å¤„ç†é”ç«äº‰ï¼š\n While we assume that heavy contention is usually rare in a well-designed DBMS, some workloads make it unavoidable. The lock should, thus, handle contention gracefully without sacrificing its fast, uncondented path.\n åŒæ—¶æœ€å¥½ä¹Ÿè¦èƒ½å¤Ÿå‘¨æœŸæ€§çš„æ£€æŸ¥æ˜¯å¦æœ‰è¢« cancelï¼š\n for example, that the user wants to cancel a long-running query, but the working thread is currently sleeping while waiting for a lock. Waiting too long can lead to an unpleasant user experience. For this reason, it would be desirable if the lockâ€™s API would allow one to incorporate periodic cancellation checks while a thread is waiting.\n Locking Technioques åœ¨æ•°æ®åº“ä¸­ï¼Œæˆ‘ä»¬å¯¹ lock çš„éœ€æ±‚æ˜¯æ—¢è¦æœ€å°åŒ– overhead åˆè¦æœ€å¤§åŒ– scalabilityã€‚æœ€è¿‘çš„ä¸€äº›ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé™¤äº†åœ¨ write-heavy çš„åœºæ™¯é‡Œ pessimistic locking çš„ä¼˜åŠ¿ä¼šæ›´å¤§ä»¥å¤–ï¼Œå…¶ä»–åœºæ™¯ä¸­ Optimistic Locking ç›¸æ¯” pessimistic locking æˆ–è€… lock-free éƒ½æœ‰æ›´å¥½çš„æ€§èƒ½å’Œå…¶ä»–ä¼˜åŠ¿ã€‚è¿™é‡Œä½œè€…ç½—åˆ—äº†å‡ ä¸ªå¸¸è§çš„ Optimistic locking å’Œå®ƒä»¬çš„ä¼˜ç¼ºç‚¹ï¼Œè¯¦ç»†ä»‹ç»äº†ç›®å‰åœ¨ Umbra ä¸­ä½¿ç”¨çš„ Hybrid Lock è®¾è®¡å’Œå®ç°ç»†èŠ‚ã€‚\nOptimistic Locking Optimistic Locking çš„åŸºæœ¬æ€è·¯æ˜¯æ£€æŸ¥åœ¨è¯»æ•°æ®çš„æ—¶å€™æ²¡æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨ä¿®æ”¹å®ƒã€‚Optimistic locking ä¼šç»´æŠ¤ä¸€ä¸ªç‰ˆæœ¬å·ï¼Œæ¯æ¬¡ä¿®æ”¹æ•°æ®éƒ½å¢åŠ è¿™ä¸ªç‰ˆæœ¬å·ã€‚è¯»çš„æ—¶å€™å¦‚æœå‘ç° encode åœ¨ç‰ˆæœ¬å·ä¸­çš„ lock æ¯”ç‰¹ä½ä¸º 1ï¼Œæˆ–è€…è¯»å–æ•°æ®åç‰ˆæœ¬å·å‘ç”Ÿäº†å˜åŒ–ï¼Œè¿™æ¬¡è¯»æ“ä½œå°±éœ€è¦é‡è¯•ã€‚ä¸Šå›¾çš„ä¼ªä»£ç å±•ç¤ºäº†ä¸€ä¸ªå¯èƒ½ fallback åˆ° pessimistic lock çš„ optimistic lock å®ç°ï¼Œæ¨æµ‹ isLocked(preVersion) å°±æ˜¯åœ¨æ£€æŸ¥ lock æ¯”ç‰¹ä½ã€‚\nOptimistic Locking å’Œ Pessimistic Lock çš„æ€§èƒ½å·®å¼‚åŸå› ä¸»è¦å‡ºç°åœ¨ cache line ä¸Šï¼š\n Optimistic locking avoids atomic writes and its cache line stays in shared mode. Pessimistic locks must always modify the cache line and thus their performance is bound by cache-coherency latencies\n Optimistic locking ç‰¹åˆ«é€‚åˆç”¨åœ¨ç»å¸¸è¯»çš„çƒ­ç‚¹æ•°æ®ä¸Šï¼Œæ¯”å¦‚ B Tree çš„ root èŠ‚ç‚¹ã€‚ä½¿ç”¨æ—¶éœ€è¦æ³¨æ„å‡ ä¸ªé—®é¢˜ï¼š\n Optimistic locking åœ¨ç¢°åˆ°å†™çš„æ—¶å€™ä¼šé‡è¯•æ­£åœ¨è¿›è¡Œçš„è¯»æ“ä½œï¼Œéœ€è¦ç¡®ä¿é‡è¯•æ—¶ä¸ä¼šå‘ç”Ÿå¼‚å¸¸ã€‚æ¯”å¦‚è¯»å–æŸä¸ª B Tree èŠ‚ç‚¹ï¼Œå¯èƒ½åˆ«çš„çº¿ç¨‹è§¦å‘äº† B Tree Merge æ“ä½œå¯¼è‡´å½“å‰è¦è¯»çš„èŠ‚ç‚¹è¢«åˆ é™¤äº†ï¼Œéœ€è¦ç¡®ä¿é‡è¯•æ—¶è®¿é—®è¿™ä¸ªèŠ‚ç‚¹ä¸ä¼šå‡ºç°è®¿é—® null pointer çš„æƒ…å†µã€‚LeanStore å’Œä½œè€…æåˆ°çš„ Adaptive Radix Tree å¯ä»¥é€šè¿‡ Epoch æœºåˆ¶æ¥ç¡®ä¿ä¸ä¼šå‘ç”Ÿè¿™ä¸ªé—®é¢˜ æ³¨æ„ä¸Šé¢ä¼ªä»£ç ä¼ å…¥çš„æ˜¯ä¸€ä¸ª readCallBackï¼Œè¿™ä¸ª callback æ¯æ¬¡é‡è¯•éƒ½ä¼šè¢«è°ƒç”¨ï¼Œå¦‚æœåœ¨é‡Œé¢æ›´æ–°ä¸€äº›å€¼ï¼Œæ¯”å¦‚æ±‚ countï¼Œé‚£ä¹ˆå¯èƒ½å°±ä¼šå› ä¸ºé‡è¯•å¾—åˆ°é”™è¯¯ç»“æœã€‚æœ€å®‰å…¨çš„åšæ³•æ˜¯ä»…é€šè¿‡è¿™ä¸ª callback è·å–å€¼åå°± buffer ä½ï¼Œç­‰æ•´ä¸ªè¯»æ“ä½œè¿”å›åæ‰ç”¨è¯»åˆ°çš„å€¼å»åšä¸‹ä¸€æ­¥çš„è®¡ç®— å½“å¾ˆå¤šçº¿ç¨‹å¹¶å‘å†™æ—¶ï¼Œoptimistic lock å¾ˆå®¹æ˜“è¢«é¥¿æ­»ï¼Œæ‰€ä»¥å°±åƒä¼ªä»£ç æè¿°çš„é‚£æ ·ï¼Œåœ¨ç»å†äº†æœ€å¤§é‡è¯•æ¬¡æ•°åéœ€è¦èƒ½å¤Ÿ fallback åˆ° pessimistic lock  Speculative Locking (HTM) Speculative locking æ˜¯ Intel åœ¨ç¡¬ä»¶ä¸Šæ”¯æŒçš„ä¸€ç§ optimistic lockingã€‚å³ä½¿æ˜¯å¤šä¸ªå†™çº¿ç¨‹ä¹Ÿå¯ä»¥åŒæ—¶æŒæœ‰è¿™ä¸ª lockï¼Œåªè¦å®ƒä»¬æ²¡æœ‰å‡ºç°å†™å†²çªã€‚è¿™ä¸ª lock æœ‰å¾ˆå¤šé™åˆ¶ï¼š\n All conflicts are detected on L1-cache line granularity (usually 64 bytes) and the addresses of the joint read/write-set must fit into L1 cache. Additionally, the critical section should be short to avoid interrupts or context switches and must avoid certain system calls.\n Speculative locking è¿™ç§åŸºäºç¡¬ä»¶çš„ lock æœ€ä¸»è¦çš„ç¼ºç‚¹å°±æ˜¯å®ƒå’Œç¡¬ä»¶ç»‘å®šï¼Œä¸å¤Ÿé€šç”¨ã€‚åªæœ‰æ¯”è¾ƒæ–°çš„ Intel å’Œ ARM å¤„ç†å™¨æ‰æ”¯æŒç±»ä¼¼çš„åŠŸèƒ½ã€‚è€ƒè™‘åˆ°ä¸Šé¢æåˆ°çš„ä½¿ç”¨é™åˆ¶ï¼Œä»¥åŠä¸€äº›å¤„ç†å™¨å¯èƒ½æ²¡æœ‰è¿™ä¸ªåŠŸèƒ½ï¼Œä½¿ç”¨è€…é€šå¸¸éƒ½éœ€è¦å®ç°ä¸€ä¸ª fallback åˆ°ä¼ ç»Ÿ lock çš„æœºåˆ¶æ¥åº”å¯¹è¿™äº›é—®é¢˜ã€‚\nHybrid Locking é‡è¯»å°‘å†™çš„åœºæ™¯å¯ä»¥ä½¿ç”¨ optimistic locking è·å–æœ€å¥½çš„æ€§èƒ½ï¼Œè¯»å†™æ··åˆçš„åœºæ™¯å°±éœ€è¦ç”¨åˆ° pessimistic locking äº†ã€‚ä»ä¸Šé¢çš„è¡¨æ ¼æ¥çœ‹ï¼Œä¸ç®¡æ˜¯ write-heavy è¿˜æ˜¯ write-only åœºæ™¯ï¼Œä½¿ç”¨ shared lock éƒ½æ˜¯ä¸€ä¸ªæ›´å¥½çš„ pessimistic locking é€‰æ‹©ã€‚\nè¦åœ¨ä¸åŒåœºæ™¯éƒ½è·å¾—æœ€å¥½çš„æ€§èƒ½ï¼Œå°±éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡å¯¹åŒä¸€ä¸ªæ•°æ®ä¸Šä¸åŒçš„é”ã€‚æ¯”å¦‚ B Treeï¼Œè®¿é—® read-contended ä¸Šå±‚èŠ‚ç‚¹å°±å¯ä»¥ä½¿ç”¨ optimistic lockingï¼Œè€Œè®¿é—®å¶å­ç»“ç‚¹å» scan ä¸Šé¢çš„æ•°æ®æ—¶å°±æœ€å¥½ä½¿ç”¨ pessimistic locking é¿å…ä»£ä»·é«˜æ˜‚çš„å†²çªé‡è¯•ã€‚\nä¸ºäº†è¾¾åˆ°è¿™ä¸ªç›®æ ‡ï¼Œä½œè€…è®¾è®¡äº†ä¸€ä¸ª Hybrid-Lockã€‚å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™ä¸ª Hybrid-Lock å†…éƒ¨åŒæ—¶åŒ…å« RWMutex å’Œ atomic åˆ†åˆ«ç”¨æ¥åš Pessimistic Lock å’Œ Optimistic Lockã€‚\nç†è®ºä¸Šä¹Ÿå¯ä»¥æŠŠè¿™ä¸ª RWMutex å’Œ version é€šè¿‡ä¸€ä¸ª 64 ä½æ•´æ•°æ¥å®ç°ã€‚æŠŠä»–ä»¬åˆ†å¼€åï¼Œå®ç°èµ·æ¥ç®€å•ç›´æ¥ä¸å®¹æ˜“å‡ºé—®é¢˜ï¼Œä¸º Hybrid-Lock å®ç°å„ç§ RWMutex å·²æœ‰çš„æ¥å£ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œæ¯”å¦‚ä¸‹å›¾ HybridLock çš„ lockShared()ã€unlockShared()ã€lockExclusive()ã€unlockExclusive() å°±ç›´æ¥ç›´æ¥ä½¿ç”¨äº†å†…éƒ¨çš„ RWMutex()ã€‚\nè¿˜æ˜¯ä»¥ B Tree ä¸ºä¾‹è€ƒè™‘è¿™ä¹ˆä¸€ç§æƒ…å†µï¼šä¸€ä¸ªè¯»çº¿ç¨‹é€šè¿‡è°ƒç”¨ tryReadOptimistically() æ¥è®¿é—®æŸä¸ªä¸­é—´èŠ‚ç‚¹ï¼ŒtryReadOptimistically() åˆšå¼€å§‹æ‰§è¡Œæ—¶æ²¡æœ‰ä»»ä½•å…¶ä»–çº¿ç¨‹è¯»å†™è¿™ä¸ªèŠ‚ç‚¹ï¼Œè¯¥å‡½æ•°é¡ºåˆ©æ‰§è¡Œåˆ°äº† readCallback()ï¼Œä½†åœ¨ readCallback() æ‰§è¡Œä¸­å¦ä¸€ä¸ªçº¿ç¨‹é€šè¿‡ lockExcluseive() å¯¹è¿™ä¸ªèŠ‚ç‚¹ä¸Šé”ï¼Œä¿®æ”¹è¿™ä¸ªèŠ‚ç‚¹çš„å†…å®¹ï¼Œæœ€åé€šè¿‡ unlockExclusive() é‡Šæ”¾é”ã€‚å¦‚æœ unlockExclusive() å…ˆé‡Šæ”¾äº† RWMutex çš„ lock è€Œæ²¡æœ‰å®Œæˆ version +1ï¼Œé‚£ä¹ˆè¯»çº¿ç¨‹å› ä¸ºæ˜¯å…ˆæ£€æŸ¥ lock å†æ£€æŸ¥ version å°±å¯èƒ½è¯»åˆ°é”™è¯¯çš„å€¼ã€‚\néœ€è¦ç‰¹åˆ«æ³¨æ„ unlockExclusive() é‡Œé¢ä¸¤ä¸ªæ“ä½œçš„é¡ºåºã€‚å› ä¸º tryReadOptimistically() åœ¨æ‰§è¡Œå®Œ readCallBack åå…ˆæ£€æŸ¥ RWMutex å†æ£€æŸ¥ versionï¼ŒunlockExclusive() é‡Œé¢å°±éœ€è¦å…ˆ version +1 å†é‡Šæ”¾ RWMutexï¼Œç¡®ä¿è¯»æ“ä½œä¸€å®šèƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ä¸ªè¯»å†™å†²çªå¹¶é‡è¯•ã€‚åœ¨ Intel å¹³å°ä¸Šä¹Ÿå¯ä»¥ä½¿ç”¨ CMPXCHG16B æŒ‡ä»¤æ¥åŒæ—¶æ›´æ–° version å’Œé‡Šæ”¾é”ã€‚\nreadOptimisticIfPossible() å’Œä¸€å¼€å§‹åœ¨ Optimistic Locking ä¸­çœ‹åˆ°çš„ä¼ªä»£ç å·¥ä½œæœºåˆ¶ç¨å¾®æœ‰ç‚¹åŒºåˆ«ã€‚å®ƒä¼šåœ¨ tryReadOptimistically() å¤±è´¥åç›´æ¥ä»å›é€€åˆ° pessimistic locking æ¨¡å¼ï¼Œä½¿ç”¨ lockShared() å’Œ unLockShared() å®Œæˆè¿™æ¬¡è¯»æ“ä½œã€‚\nHybrid-Lock å†åŠ ä¸Šåé¢æå‡ºçš„ ParkingLot çš„ lock contention å¤„ç†ç­–ç•¥å°±æ˜¯ç›®å‰ Umbra ä¸­ä½¿ç”¨çš„é”å®ç°ï¼Œæ›¿ä»£äº†ä¹‹å‰æåˆ°çš„ Versioned Latch æ–¹æ¡ˆã€‚ä¸‹é¢å°±æ˜¯ Hybrid Lock çš„ä¼ªä»£ç å®ç°ã€‚\nContention Handling é”å†²çªæ˜¯å¾ˆéš¾é¿å…çš„ï¼Œæ¯”å¦‚åœ¨ write-heavy åœºæ™¯æ‰€æœ‰çº¿ç¨‹éƒ½ä½¿ç”¨ pessimistic locking æ—¶ï¼ŒHybrid Lock ä¸­çš„ RWMutex ä¸Šå°±å¯èƒ½å‘ç”Ÿé”å†²çªã€‚å¦‚ä½•é«˜æ•ˆå¤„ç†é”å†²çªï¼Œå¹¶ä¸”åœ¨çº¿ç¨‹ç­‰é”æœŸé—´èƒ½å¤Ÿè¯†åˆ«åˆ° query è¢« cancel åŠæ—¶åœæ­¢ query æ‰§è¡Œå‘¢ï¼Ÿ\nè¿™ä¸ªç« èŠ‚ä½œè€…åˆ†æäº† Hybrid Lock å¯èƒ½çš„ RWMutex å®ç°ï¼Œæœ€ç»ˆé‡‡ç”¨äº† Parking Lot çš„æ–¹æ¡ˆã€‚\nBusy-Waiting/Spinning Spinning æ˜¯ä¸€ç§å¸¸è§çš„å¤„ç†æ–¹å¼ï¼Œå’Œ Spinlock ä¸€æ ·ã€‚Spinning çš„ä¸€äº›ç¼ºç‚¹ï¼š\n Spinning can lead to priority inversion, as spinning threads seem very busy to a scheduler they might receive higher priority than a thread that does useful work. Especially in the case of over-subscription, this can cause critical problems Heavy spinning wastes resources and energy [6] and increases cache pollution, which is caused by additional bus traffic. ä½œè€…é€šè¿‡ cache line çš„ä¾‹å­è¯¦ç»†è§£é‡Šäº†è¿™ä¸ªé—®é¢˜ï¼šFollowing the MESI-protocol, every atomic write needs to invalidate all existing copies in other cores. Ideally, a core owns a cache line exclusively and does not need to send any invalidation messages. However, if other threads are spinning on the same lock, they constantly request this cache line, causing contention. The negative effects are worst when the waiting thread does write-for-ownership cycles, as those cause expensive invalida- tion messages. For this reason, a waiting thread should use the test-test-and-set pattern and only do the write-for-ownership cycle when it sees that the lock is available. In other words, it only reads the lock state in the busy loop to keep the lockâ€™s cache line in shared mode. å’Œ lock å¤„äºåŒä¸€ cache line çš„æ•°æ®ä¹Ÿä¼šå—åˆ°å½±å“ï¼Œä¹Ÿå°±æ˜¯ false-sharing çš„é—®é¢˜ã€‚spinning can still lead to cache pollution when the protected data is on the same cache line as the lock itself (cf. Figure 3). By spinning on the lock the waiting thread ğ‘‡ğ‘¤ğ‘ğ‘–ğ‘¡ constantly loads the cache line in shared mode. Whenever the lock owning ğ‘‡hğ‘ğ‘ ğ¿ğ‘œğ‘ğ‘˜ updates the protected data, it must invalidate ğ‘‡ğ‘¤ğ‘ğ‘–ğ‘¡ â€™s copy of the cache line. Having to send these invalidation messages, slows down ğ‘‡hğ‘ğ‘ ğ¿ğ‘œğ‘ğ‘˜ and increases the time spent in the critical section.  è™½ç„¶ç°æœ‰æ–¹æ¡ˆé€šè¿‡ backoff ç­–ç•¥å¯ä»¥ç¼“è§£ spinlock çš„è¿™äº›é—®é¢˜ï¼Œä½†è¿™äº›ç­–ç•¥æœ¬èº«ä¹Ÿä¸æ˜¯å¾ˆå®Œç¾ï¼š\n there exist several backoff strate- gies that add pause instructions to put the CPU into a lower power state, or call sched_yield to encourage the scheduler to switch to another thread. However, since the scheduler cannot guess when the thread wants to proceed, yielding is generally not recommended as its behavior is largely unpredictable [31].\n Local Spinning using Queuing spinning å¸¦æ¥çš„ cache contention é—®é¢˜åœ¨ NUMA æ¶æ„ä¸Šä¼šæ›´ä¸¥é‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸€äº› spinlock çš„å®ç°åª spin è¿™ä¸ª lock çš„ thread-local å‰¯æœ¬ï¼Œæ¯”å¦‚ MCS-lock æˆ–è€… Krieger et al. åœ¨ [13, 25] æå‡ºçš„ read-write mutexã€‚\nè¿™ç§ lock çš„å·¥ä½œæ–¹å¼ï¼š\n When acquiring a lock, every thread creates a thread-local instance of the lock structure including its lock state and a next pointer to build a linked list of waiting threads.3 Then, it exchanges the next pointer of the global lock, making it point to its own local instance. If the previous next entry was nil, the lock acquisition was successful. Otherwise, if the entry already pointed to another instance, the thread enqueues itself in the wait- ing list by updating the next-pointer of the found instance (current tail) to itself.\n Ticket Spinlock ticket spinlock æ˜¯å¦ä¸€ç§ spinlockï¼Œguarantees fairness without using queuesã€‚\nå®ƒçš„å·¥ä½œæ–¹å¼ï¼š\n maintaining two counters: next-ticket and now-serving. A thread gets a ticket using an atomic fetch_and_add and waits until its ticket number matches that of now-serving.\n é™¤äº†èƒ½å¤Ÿä¿è¯ fairness ä»¥å¤–ï¼Œå®ƒè¿˜æœ‰å…¶ä»–ä¼˜ç‚¹ï¼š\n this also enables more precise backoff in case of contention by estimating the wait time. The wait time can be estimated by multiplying the position in the queue and the expected time spent in the critical section. Mellor-Crummey and Scott argue that it is best to use the minimal possible time for the critical section, as overshooting in backoff will delay all other threads in line due to the FIFO nature\n Kernel-Supported ParkingLot ä¸Šé¢æåˆ°çš„ spinlock å§‹ç»ˆå­˜åœ¨ over-subscription æˆ–è€… waste of energy çš„é—®é¢˜ã€‚å› æ­¤å¾ˆå¤šåº“çš„é”å®ç°ï¼ˆæ¯”å¦‚ pthread mutexï¼‰éƒ½åŸºäº Linux å†…æ ¸æä¾›çš„ kernel-level locking æ¥ suspend å½“å‰è¿™ä¸ªçº¿ç¨‹ç›´åˆ°æ‹¿åˆ°è¿™ä¸ª lock ä¸ºæ­¢ã€‚\nä½†å†…æ ¸ä¸Šçš„ç³»ç»Ÿè°ƒç”¨å¼€é”€æ˜¯å¾ˆé«˜çš„ï¼Œæ‰€ä»¥ä¹Ÿæœ‰ä¸€äº›è‡ªé€‚åº”çš„é”å®ç°ï¼Œä»…é”å†²çªçš„æ—¶å€™æ‰è°ƒç”¨ kernel é˜»å¡å½“å‰çº¿ç¨‹ï¼Œæ¯”å¦‚ Linux æä¾›çš„ futexã€‚\nåŸºäº futex çš„æ€è·¯ï¼ŒWebKit æå‡ºäº†ä¸€ä¸ªå« Parking Lot çš„è‡ªé€‚åº”é”ã€‚ä¹Ÿæ˜¯ Umbra ç›®å‰æ­£åœ¨ä½¿ç”¨çš„é”å®ç°ã€‚Parking Lot ç”¨ä¸€ä¸ªå…¨å±€å“ˆå¸Œè¡¨æ¥å­˜å‚¨ lock åˆ° wait queue çš„æ˜ å°„å…³ç³»ã€‚å’Œ Linux futex ä¸ä¸€æ ·ï¼Œè¿™ç§å®ç°æ–¹å¼æ›´åŠ é€šç”¨ï¼Œå¯ç§»æ¤æ€§å¼ºï¼Œä¸ä¾èµ–å…¶éæ ‡å‡†çš„æˆ–è€…ç‰¹å®šå¹³å°çš„ç³»ç»Ÿè°ƒç”¨ã€‚å®ƒä¹Ÿæ›´åŠ çµæ´»ï¼Œæ¯”å¦‚åœ¨ Parking çš„æ—¶å€™å¯ä»¥æ‰§è¡ŒæŸä¸ª callback å‡½æ•°ã€‚Umbra åˆ©ç”¨è¿™ä¸ªç‰¹æ€§åœ¨é”ç­‰å¾…æ—¶æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦è¢«å–æ¶ˆï¼ŒPage æ˜¯å¦å·²ç»è¢«ç¼“å­˜æ›¿æ¢ç­‰ã€‚\nä¸Šå›¾æè¿°äº† Umbra ä¸­å®ç°çš„ Parking Lot é”ã€‚å½“çº¿ç¨‹è·å–é”åä¼šå°† lock bit (L) è®¾ç½®ä¸º 1ã€‚å½“å¦ä¸€ä¸ªçº¿ç¨‹å†æ¬¡è·å–é”æ—¶ï¼Œå®ƒä¼šåœ¨ parking lot ä¸­ç­‰å¾…ã€‚æ­¤æ—¶å®ƒä¼šæŠŠé”çš„ wait bit (W) è®¾ç½®ä¸º 1 è¡¨ç¤ºæœ‰äººæ­£åœ¨ç­‰é”ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªé”çš„åœ°å€åœ¨å“ˆå¸Œè¡¨ä¸­æ‰¾åˆ°è¯¥é”å¯¹åº”çš„ parking spaceã€‚å¦‚æœä»æ—§æ»¡è¶³ç”¨æˆ·è‡ªå®šä¹‰çš„ wait conditionï¼Œè¯¥çº¿ç¨‹å¼€å§‹ç­‰å¾…è¿™ä¸ª condition variableã€‚å½“ç¬¬ 1 ä¸ªçº¿ç¨‹é‡Šæ”¾é”åï¼Œå®ƒå‘ç° wait bit (W) ä¸º 1 çŸ¥é“æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨ç­‰é”ï¼Œå®ƒä¼šæ‰¾åˆ°è¿™ä¸ªé”å¯¹åº”çš„ parking spaceï¼Œå°†æ‰€æœ‰ç­‰å¾…çš„çº¿ç¨‹éƒ½å”¤é†’ã€‚ä¸ºäº†é¿å… parking space çš„ data race é—®é¢˜ï¼Œæ¯ä¸ª parking space éƒ½æœ‰ä¸€ä¸ª mutex æ¥ä¿æŠ¤ã€‚\nå…³äº lock bit å’Œ wait bitï¼Œä½œè€…åœ¨è®ºæ–‡çš„ 2.3 å°ç»“ä»‹ç»å®Œ Hybrid Lock åæœ‰ä¸ªè¡¥å……è¯´æ˜ï¼Œæ”¾åˆ°è¿™é‡Œæˆ‘ä»¬äº†è§£åˆ° parking lot åå°±æ¯”è¾ƒå®¹æ˜“ç†è§£äº†ï¼š\n wait bitï¼šencode åœ¨ Hybrid-Lock çš„ RWMutex ä¸Šï¼Œç”¨æ¥è¡¨ç¤ºæœ‰å…¶ä»–çº¿ç¨‹ç­‰é” lock bitï¼šencode åœ¨ Hybrid-Lock çš„ version ä¸Šï¼Œæ£€æµ‹åˆ°æœ‰é”åå½“å‰çº¿ç¨‹éœ€è¦è°ƒç”¨ä¸‹é¢ä¼ªä»£ç ä¸­çš„ park() å‡½æ•°è¿›å…¥ parking çŠ¶æ€ï¼Œç›´åˆ°è¢« condition variable å”¤é†’ã€‚  Parking lot æœ¬è´¨ä¸Šå°±æ˜¯ä¸ªå›ºå®š 512 æ§½ä½çš„å“ˆå¸Œè¡¨ï¼Œå› ä¸ºå†²çªçš„é”æ•°é‡æœ€å¤šä¸ä¼šè¶…è¿‡ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼Œæ‰€ä»¥ 512 ä¸ªæ§½ä½å°±è¶³å¤Ÿç”¨äº†ã€‚é‡‡ç”¨æ‹‰é“¾æ³•è§£å†³å“ˆå¸Œå†²çªã€‚\nå½“æ‰§è¡Œç”¨æˆ· query çš„çº¿ç¨‹åœ¨ parking space ä¸­ç­‰å¾…æ—¶ï¼Œæ¯ 10ms ä¼šè¢«å”¤é†’æ£€æŸ¥å½“å‰ query æ˜¯å¦è¢«å–æ¶ˆäº†ï¼Œä»¥ä¾¿åœæ­¢ç­‰å¾…åŠæ—¶ç»“æŸå½“å‰ query çš„æ‰§è¡Œã€‚\nä¸‹é¢æ˜¯ parking lot çš„ä¼ªä»£ç ã€‚è™½ç„¶éå¸¸ç®€å•ç›´æ¥ï¼Œä½†ä½¿ç”¨éœ€è¦ç‰¹åˆ«å°å¿ƒã€‚éœ€è¦ç¡®ä¿é€ æˆçº¿ç¨‹ç­‰å¾…çš„ä¿¡æ¯ä¸ä¼šä¸¢å¤±å¯¼è‡´çº¿ç¨‹æ— é™æœŸçš„ç­‰å¾…ä¸‹å»ï¼Œä»»ä½•ä¿®æ”¹è¿™äº›æ•°æ®çš„çº¿ç¨‹éƒ½éœ€è¦æ£€æŸ¥é”çš„ wait bitï¼Œåœ¨å¿…è¦æ—¶å”¤é†’æ‰€æœ‰ç­‰å¾…çš„çº¿ç¨‹ã€‚ä½œè€…è¿™é‡Œæ²¡ä¸¾ä¾‹å­ï¼Œæˆ‘èƒ½æƒ³åˆ°çš„ä¸€ä¸ªåœºæ™¯æ˜¯ B Tree Node è¢«ç¼“å­˜æ›¿æ¢çš„åœºæ™¯ã€‚\nè®ºæ–‡åˆ°è¿™ï¼ˆç¬¬ 5 é¡µï¼‰æ ¸å¿ƒå†…å®¹å°±ç»“æŸäº†ï¼Œåé¢èŠ±äº†å¤§é‡çš„ç¯‡å¹…ä»‹ç»å’Œå±•ç¤ºä½œè€…çš„æµ‹è¯•ç»“æœã€‚\nEvaluation TPC-C and TPC-H Lock Granularity Space Consumption Efficiency of Lock Acquisition Contention Handling Strategies RELATED WORK CONCLUSION ","wordCount":"4195","inLanguage":"en","datePublished":"2023-04-05T00:00:00Z","dateModified":"2023-04-05T00:00:00Z","author":{"@type":"Person","name":"Jian"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zz-jason.github.io/posts/vldb-2023-scalable-and-robust-latches/"},"publisher":{"@type":"Organization","name":"Jian Zhang","logo":{"@type":"ImageObject","url":"https://zz-jason.github.io/favicon.ico"}}}</script></head><body id=top><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://zz-jason.github.io/ accesskey=h title="Jian Zhang (Alt + H)">Jian Zhang</a>
<span class=logo-switches></span></div><ul id=menu onscroll=menu_on_scroll()><li><a href=https://zz-jason.github.io/ title=Home><span>Home</span></a></li><li><a href=https://zz-jason.github.io/categories/ title=Categories><span>Categories</span></a></li><li><a href=https://zz-jason.github.io/posts/ title=Archives><span>Archives</span></a></li><li><a href=https://zz-jason.github.io/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>[VLDB 2023] Scalable and Robust Latches for Database Systems</h1><div class=post-meta>April 5, 2023&nbsp;Â·&nbsp;9 min&nbsp;Â·&nbsp;Jian</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#introduction aria-label=Introduction>Introduction</a></li><li><a href=#locking-technioques aria-label="Locking Technioques">Locking Technioques</a><ul><li><a href=#optimistic-locking aria-label="Optimistic Locking">Optimistic Locking</a></li><li><a href=#speculative-locking-htm aria-label="Speculative Locking (HTM)">Speculative Locking (HTM)</a></li><li><a href=#hybrid-locking aria-label="Hybrid Locking">Hybrid Locking</a></li></ul></li><li><a href=#contention-handling aria-label="Contention Handling">Contention Handling</a><ul><li><a href=#busy-waitingspinning aria-label=Busy-Waiting/Spinning>Busy-Waiting/Spinning</a></li><li><a href=#local-spinning-using-queuing aria-label="Local Spinning using Queuing">Local Spinning using Queuing</a></li><li><a href=#ticket-spinlock aria-label="Ticket Spinlock">Ticket Spinlock</a></li><li><a href=#kernel-supported-parkinglot aria-label="Kernel-Supported ParkingLot">Kernel-Supported ParkingLot</a></li></ul></li><li><a href=#evaluation aria-label=Evaluation>Evaluation</a><ul><li><a href=#tpc-c-and-tpc-h aria-label="TPC-C and TPC-H">TPC-C and TPC-H</a></li><li><a href=#lock-granularity aria-label="Lock Granularity">Lock Granularity</a></li><li><a href=#space-consumption aria-label="Space Consumption">Space Consumption</a></li><li><a href=#efficiency-of-lock-acquisition aria-label="Efficiency of Lock Acquisition">Efficiency of Lock Acquisition</a></li><li><a href=#contention-handling-strategies aria-label="Contention Handling Strategies">Contention Handling Strategies</a></li></ul></li><li><a href=#related-work aria-label="RELATED WORK">RELATED WORK</a></li><li><a href=#conclusion aria-label=CONCLUSION>CONCLUSION</a></li></ul></div></details></div><div class=post-content><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Efficient and scalable synchronization is one of the key require- ments for systems that run on modern multi-core processors.</p><p>ä½†æ˜¯è™½ç„¶æœ‰å¾ˆå¤šç±»å‹çš„ Lockï¼Œä½†æ˜¯å´æ²¡æœ‰äººè¯¦ç»†ç ”ç©¶è¿‡ä»€ä¹ˆæ ·çš„ Lock é€‚ç”¨äºæ•°æ®åº“çš„å·¥ä½œè´Ÿè½½ï¼Œä¸»è¦åŸå› æ˜¯æ•°æ®åº“çš„å·¥ä½œè´Ÿè½½èŒƒå›´å¾ˆå¤§ï¼Œæœ‰ write-heavy OLTP äº‹åŠ¡ï¼Œä¹Ÿæœ‰ read-only çš„ OLAP æŸ¥è¯¢ï¼Œç”šè‡³æ˜¯ä¸¤è€…éƒ½æœ‰çš„ HTAP è´Ÿè½½ã€‚</p><p>åœ¨è®¾è®¡ Umbra çš„æ—¶å€™ï¼Œä½œè€…å¼€å§‹è°ƒç ”ä¸åŒçš„é”æœºåˆ¶å’Œä»–ä»¬ä¹‹é—´çš„æ•ˆç‡å·®å¼‚ã€‚é¦–å…ˆç¬¬ä¸€ä¸ªå‘ç°æ˜¯ä¸å¯èƒ½æœ‰ä¸€ç§é”æœºåˆ¶åœ¨æ‰€æœ‰å·¥ä½œè´Ÿè½½å’Œæ‰€æœ‰ç¡¬ä»¶ç¯å¢ƒä¸­éƒ½æ˜¯æœ€ä¼˜çš„ã€‚How- ever, we noticed that there are some re-occurring best practices for locking and synchronizationã€‚äºæ˜¯ä½œè€…ä»¬é¦–å…ˆæ€»ç»“äº†æ•°æ®åº“åœ¨ Lock ä¸Šçš„éœ€æ±‚ï¼Œç„¶å address them by analyzing and evaluating different locking techniques accordinglyã€‚</p><p>é‚£å¯¹æ•°æ®åº“å‹å¥½çš„ Lock éœ€è¦å…·å¤‡ä»€ä¹ˆæ ·çš„åŠŸèƒ½å‘¢ï¼Ÿ</p><p>è¯»æ˜¯éœ€è¦åˆå¿«æœ‰èƒ½ scale çš„ï¼š</p><blockquote><p>In general, most database workloads, even OLTP transac- tions, mostly read data, and thus reading should be fast and scalable.</p></blockquote><p>åœ¨ LLVM JIT çš„æƒ…å†µä¸‹ï¼Œçº¯ç²¹ä½¿ç”¨ OS æä¾›çš„ Lock ä¸å¤ªè¡Œï¼š</p><blockquote><p>Many modern in-memory database systems compile queries to efficient machine code to keep the latency as low as possible [26]. A lock should therefore integrate well with query compilation and avoid external function calls. This requirement makes pure OS- based locks unattractive for frequent usage during query execution.</p></blockquote><p>å› ä¸º Lock éœ€è¦ä¿æŠ¤ä¸€äº›ç»†ç²’åº¦çš„æ•°æ®ç»“æ„ï¼ŒLock æœ¬èº«çš„ç©ºé—´å¼€é”€åº”è¯¥å°½é‡å°ï¼š</p><blockquote><p>To protect fine-granular data like index nodes, or hash table buckets, the lock itself should be space efficient. This does not necessarily mean minimal, but it should also not waste unreasonable amount of space. For instance, a std::mutex (40-80 bytes) would almost double the size required for an ART node [17].</p></blockquote><p>Lock è¿˜éœ€è¦èƒ½å¤Ÿé«˜æ•ˆçš„å¤„ç†é”ç«äº‰ï¼š</p><blockquote><p>While we assume that heavy contention is usually rare in a well-designed DBMS, some workloads make it unavoidable. The lock should, thus, handle contention gracefully without sacrificing its fast, uncondented path.</p></blockquote><p>åŒæ—¶æœ€å¥½ä¹Ÿè¦èƒ½å¤Ÿå‘¨æœŸæ€§çš„æ£€æŸ¥æ˜¯å¦æœ‰è¢« cancelï¼š</p><blockquote><p>for example, that the user wants to cancel a long-running query, but the working thread is currently sleeping while waiting for a lock. Waiting too long can lead to an unpleasant user experience. For this reason, it would be desirable if the lockâ€™s API would allow one to incorporate periodic cancellation checks while a thread is waiting.</p></blockquote><h2 id=locking-technioques>Locking Technioques<a hidden class=anchor aria-hidden=true href=#locking-technioques>#</a></h2><p>åœ¨æ•°æ®åº“ä¸­ï¼Œæˆ‘ä»¬å¯¹ lock çš„éœ€æ±‚æ˜¯æ—¢è¦æœ€å°åŒ– overhead åˆè¦æœ€å¤§åŒ– scalabilityã€‚æœ€è¿‘çš„ä¸€äº›ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œé™¤äº†åœ¨ write-heavy çš„åœºæ™¯é‡Œ pessimistic locking çš„ä¼˜åŠ¿ä¼šæ›´å¤§ä»¥å¤–ï¼Œå…¶ä»–åœºæ™¯ä¸­ Optimistic Locking ç›¸æ¯” pessimistic locking æˆ–è€… lock-free éƒ½æœ‰æ›´å¥½çš„æ€§èƒ½å’Œå…¶ä»–ä¼˜åŠ¿ã€‚è¿™é‡Œä½œè€…ç½—åˆ—äº†å‡ ä¸ªå¸¸è§çš„ Optimistic locking å’Œå®ƒä»¬çš„ä¼˜ç¼ºç‚¹ï¼Œè¯¦ç»†ä»‹ç»äº†ç›®å‰åœ¨ Umbra ä¸­ä½¿ç”¨çš„ Hybrid Lock è®¾è®¡å’Œå®ç°ç»†èŠ‚ã€‚</p><h3 id=optimistic-locking>Optimistic Locking<a hidden class=anchor aria-hidden=true href=#optimistic-locking>#</a></h3><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304052144085.png alt="Listing 1: Optimistic Locking"></p><p>Optimistic Locking çš„åŸºæœ¬æ€è·¯æ˜¯æ£€æŸ¥åœ¨è¯»æ•°æ®çš„æ—¶å€™æ²¡æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨ä¿®æ”¹å®ƒã€‚Optimistic locking ä¼šç»´æŠ¤ä¸€ä¸ªç‰ˆæœ¬å·ï¼Œæ¯æ¬¡ä¿®æ”¹æ•°æ®éƒ½å¢åŠ è¿™ä¸ªç‰ˆæœ¬å·ã€‚è¯»çš„æ—¶å€™å¦‚æœå‘ç° encode åœ¨ç‰ˆæœ¬å·ä¸­çš„ lock æ¯”ç‰¹ä½ä¸º 1ï¼Œæˆ–è€…è¯»å–æ•°æ®åç‰ˆæœ¬å·å‘ç”Ÿäº†å˜åŒ–ï¼Œè¿™æ¬¡è¯»æ“ä½œå°±éœ€è¦é‡è¯•ã€‚ä¸Šå›¾çš„ä¼ªä»£ç å±•ç¤ºäº†ä¸€ä¸ªå¯èƒ½ fallback åˆ° pessimistic lock çš„ optimistic lock å®ç°ï¼Œæ¨æµ‹ <code>isLocked(preVersion)</code> å°±æ˜¯åœ¨æ£€æŸ¥ lock æ¯”ç‰¹ä½ã€‚</p><p>Optimistic Locking å’Œ Pessimistic Lock çš„æ€§èƒ½å·®å¼‚åŸå› ä¸»è¦å‡ºç°åœ¨ cache line ä¸Šï¼š</p><blockquote><p>Optimistic locking avoids atomic writes and its cache line stays in shared mode. Pessimistic locks must always modify the cache line and thus their performance is bound by cache-coherency latencies</p></blockquote><p>Optimistic locking ç‰¹åˆ«é€‚åˆç”¨åœ¨ç»å¸¸è¯»çš„çƒ­ç‚¹æ•°æ®ä¸Šï¼Œæ¯”å¦‚ B Tree çš„ root èŠ‚ç‚¹ã€‚ä½¿ç”¨æ—¶éœ€è¦æ³¨æ„å‡ ä¸ªé—®é¢˜ï¼š</p><ol><li>Optimistic locking åœ¨ç¢°åˆ°å†™çš„æ—¶å€™ä¼šé‡è¯•æ­£åœ¨è¿›è¡Œçš„è¯»æ“ä½œï¼Œéœ€è¦ç¡®ä¿é‡è¯•æ—¶ä¸ä¼šå‘ç”Ÿå¼‚å¸¸ã€‚æ¯”å¦‚è¯»å–æŸä¸ª B Tree èŠ‚ç‚¹ï¼Œå¯èƒ½åˆ«çš„çº¿ç¨‹è§¦å‘äº† B Tree Merge æ“ä½œå¯¼è‡´å½“å‰è¦è¯»çš„èŠ‚ç‚¹è¢«åˆ é™¤äº†ï¼Œéœ€è¦ç¡®ä¿é‡è¯•æ—¶è®¿é—®è¿™ä¸ªèŠ‚ç‚¹ä¸ä¼šå‡ºç°è®¿é—® null pointer çš„æƒ…å†µã€‚LeanStore å’Œä½œè€…æåˆ°çš„ Adaptive Radix Tree å¯ä»¥é€šè¿‡ Epoch æœºåˆ¶æ¥ç¡®ä¿ä¸ä¼šå‘ç”Ÿè¿™ä¸ªé—®é¢˜</li><li>æ³¨æ„ä¸Šé¢ä¼ªä»£ç ä¼ å…¥çš„æ˜¯ä¸€ä¸ª readCallBackï¼Œè¿™ä¸ª callback æ¯æ¬¡é‡è¯•éƒ½ä¼šè¢«è°ƒç”¨ï¼Œå¦‚æœåœ¨é‡Œé¢æ›´æ–°ä¸€äº›å€¼ï¼Œæ¯”å¦‚æ±‚ countï¼Œé‚£ä¹ˆå¯èƒ½å°±ä¼šå› ä¸ºé‡è¯•å¾—åˆ°é”™è¯¯ç»“æœã€‚æœ€å®‰å…¨çš„åšæ³•æ˜¯ä»…é€šè¿‡è¿™ä¸ª callback è·å–å€¼åå°± buffer ä½ï¼Œç­‰æ•´ä¸ªè¯»æ“ä½œè¿”å›åæ‰ç”¨è¯»åˆ°çš„å€¼å»åšä¸‹ä¸€æ­¥çš„è®¡ç®—</li><li>å½“å¾ˆå¤šçº¿ç¨‹å¹¶å‘å†™æ—¶ï¼Œoptimistic lock å¾ˆå®¹æ˜“è¢«é¥¿æ­»ï¼Œæ‰€ä»¥å°±åƒä¼ªä»£ç æè¿°çš„é‚£æ ·ï¼Œåœ¨ç»å†äº†æœ€å¤§é‡è¯•æ¬¡æ•°åéœ€è¦èƒ½å¤Ÿ fallback åˆ° pessimistic lock</li></ol><h3 id=speculative-locking-htm>Speculative Locking (HTM)<a hidden class=anchor aria-hidden=true href=#speculative-locking-htm>#</a></h3><p>Speculative locking æ˜¯ Intel åœ¨ç¡¬ä»¶ä¸Šæ”¯æŒçš„ä¸€ç§ optimistic lockingã€‚å³ä½¿æ˜¯å¤šä¸ªå†™çº¿ç¨‹ä¹Ÿå¯ä»¥åŒæ—¶æŒæœ‰è¿™ä¸ª lockï¼Œåªè¦å®ƒä»¬æ²¡æœ‰å‡ºç°å†™å†²çªã€‚è¿™ä¸ª lock æœ‰å¾ˆå¤šé™åˆ¶ï¼š</p><blockquote><p>All conflicts are detected on L1-cache line granularity (usually 64 bytes) and the addresses of the joint read/write-set must fit into L1 cache. Additionally, the critical section should be short to avoid interrupts or context switches and must avoid certain system calls.</p></blockquote><p>Speculative locking è¿™ç§åŸºäºç¡¬ä»¶çš„ lock æœ€ä¸»è¦çš„ç¼ºç‚¹å°±æ˜¯å®ƒå’Œç¡¬ä»¶ç»‘å®šï¼Œä¸å¤Ÿé€šç”¨ã€‚åªæœ‰æ¯”è¾ƒæ–°çš„ Intel å’Œ ARM å¤„ç†å™¨æ‰æ”¯æŒç±»ä¼¼çš„åŠŸèƒ½ã€‚è€ƒè™‘åˆ°ä¸Šé¢æåˆ°çš„ä½¿ç”¨é™åˆ¶ï¼Œä»¥åŠä¸€äº›å¤„ç†å™¨å¯èƒ½æ²¡æœ‰è¿™ä¸ªåŠŸèƒ½ï¼Œä½¿ç”¨è€…é€šå¸¸éƒ½éœ€è¦å®ç°ä¸€ä¸ª fallback åˆ°ä¼ ç»Ÿ lock çš„æœºåˆ¶æ¥åº”å¯¹è¿™äº›é—®é¢˜ã€‚</p><h3 id=hybrid-locking>Hybrid Locking<a hidden class=anchor aria-hidden=true href=#hybrid-locking>#</a></h3><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304062216400.png alt=Table1:Qualitativeoverview></p><p>é‡è¯»å°‘å†™çš„åœºæ™¯å¯ä»¥ä½¿ç”¨ optimistic locking è·å–æœ€å¥½çš„æ€§èƒ½ï¼Œè¯»å†™æ··åˆçš„åœºæ™¯å°±éœ€è¦ç”¨åˆ° pessimistic locking äº†ã€‚ä»ä¸Šé¢çš„è¡¨æ ¼æ¥çœ‹ï¼Œä¸ç®¡æ˜¯ write-heavy è¿˜æ˜¯ write-only åœºæ™¯ï¼Œä½¿ç”¨ shared lock éƒ½æ˜¯ä¸€ä¸ªæ›´å¥½çš„ pessimistic locking é€‰æ‹©ã€‚</p><p>è¦åœ¨ä¸åŒåœºæ™¯éƒ½è·å¾—æœ€å¥½çš„æ€§èƒ½ï¼Œå°±éœ€è¦æ ¹æ®ä¸Šä¸‹æ–‡å¯¹åŒä¸€ä¸ªæ•°æ®ä¸Šä¸åŒçš„é”ã€‚æ¯”å¦‚ B Treeï¼Œè®¿é—® read-contended ä¸Šå±‚èŠ‚ç‚¹å°±å¯ä»¥ä½¿ç”¨ optimistic lockingï¼Œè€Œè®¿é—®å¶å­ç»“ç‚¹å» scan ä¸Šé¢çš„æ•°æ®æ—¶å°±æœ€å¥½ä½¿ç”¨ pessimistic locking é¿å…ä»£ä»·é«˜æ˜‚çš„å†²çªé‡è¯•ã€‚</p><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304062235593.png alt="Figure 2: Hybrid-Lock"></p><p>ä¸ºäº†è¾¾åˆ°è¿™ä¸ªç›®æ ‡ï¼Œä½œè€…è®¾è®¡äº†ä¸€ä¸ª Hybrid-Lockã€‚å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¿™ä¸ª Hybrid-Lock å†…éƒ¨åŒæ—¶åŒ…å« RWMutex å’Œ atomic&lt;uint64_t> åˆ†åˆ«ç”¨æ¥åš Pessimistic Lock å’Œ Optimistic Lockã€‚</p><p>ç†è®ºä¸Šä¹Ÿå¯ä»¥æŠŠè¿™ä¸ª RWMutex å’Œ version é€šè¿‡ä¸€ä¸ª 64 ä½æ•´æ•°æ¥å®ç°ã€‚æŠŠä»–ä»¬åˆ†å¼€åï¼Œå®ç°èµ·æ¥ç®€å•ç›´æ¥ä¸å®¹æ˜“å‡ºé—®é¢˜ï¼Œä¸º Hybrid-Lock å®ç°å„ç§ RWMutex å·²æœ‰çš„æ¥å£ä¹Ÿæ¯”è¾ƒç®€å•ï¼Œæ¯”å¦‚ä¸‹å›¾ HybridLock çš„ lockShared()ã€unlockShared()ã€lockExclusive()ã€unlockExclusive() å°±ç›´æ¥ç›´æ¥ä½¿ç”¨äº†å†…éƒ¨çš„ RWMutex()ã€‚</p><p>è¿˜æ˜¯ä»¥ B Tree ä¸ºä¾‹è€ƒè™‘è¿™ä¹ˆä¸€ç§æƒ…å†µï¼šä¸€ä¸ªè¯»çº¿ç¨‹é€šè¿‡è°ƒç”¨ tryReadOptimistically() æ¥è®¿é—®æŸä¸ªä¸­é—´èŠ‚ç‚¹ï¼ŒtryReadOptimistically() åˆšå¼€å§‹æ‰§è¡Œæ—¶æ²¡æœ‰ä»»ä½•å…¶ä»–çº¿ç¨‹è¯»å†™è¿™ä¸ªèŠ‚ç‚¹ï¼Œè¯¥å‡½æ•°é¡ºåˆ©æ‰§è¡Œåˆ°äº† readCallback()ï¼Œä½†åœ¨ readCallback() æ‰§è¡Œä¸­å¦ä¸€ä¸ªçº¿ç¨‹é€šè¿‡ lockExcluseive() å¯¹è¿™ä¸ªèŠ‚ç‚¹ä¸Šé”ï¼Œä¿®æ”¹è¿™ä¸ªèŠ‚ç‚¹çš„å†…å®¹ï¼Œæœ€åé€šè¿‡ unlockExclusive() é‡Šæ”¾é”ã€‚å¦‚æœ unlockExclusive() å…ˆé‡Šæ”¾äº† RWMutex çš„ lock è€Œæ²¡æœ‰å®Œæˆ version +1ï¼Œé‚£ä¹ˆè¯»çº¿ç¨‹å› ä¸ºæ˜¯å…ˆæ£€æŸ¥ lock å†æ£€æŸ¥ version å°±å¯èƒ½è¯»åˆ°é”™è¯¯çš„å€¼ã€‚</p><p>éœ€è¦ç‰¹åˆ«æ³¨æ„ unlockExclusive() é‡Œé¢ä¸¤ä¸ªæ“ä½œçš„é¡ºåºã€‚å› ä¸º tryReadOptimistically() åœ¨æ‰§è¡Œå®Œ readCallBack åå…ˆæ£€æŸ¥ RWMutex å†æ£€æŸ¥ versionï¼ŒunlockExclusive() é‡Œé¢å°±éœ€è¦å…ˆ version +1 å†é‡Šæ”¾ RWMutexï¼Œç¡®ä¿è¯»æ“ä½œä¸€å®šèƒ½å¤Ÿæ£€æµ‹åˆ°è¿™ä¸ªè¯»å†™å†²çªå¹¶é‡è¯•ã€‚åœ¨ Intel å¹³å°ä¸Šä¹Ÿå¯ä»¥ä½¿ç”¨ <code>CMPXCHG16B</code> æŒ‡ä»¤æ¥åŒæ—¶æ›´æ–° version å’Œé‡Šæ”¾é”ã€‚</p><p>readOptimisticIfPossible() å’Œä¸€å¼€å§‹åœ¨ Optimistic Locking ä¸­çœ‹åˆ°çš„ä¼ªä»£ç å·¥ä½œæœºåˆ¶ç¨å¾®æœ‰ç‚¹åŒºåˆ«ã€‚å®ƒä¼šåœ¨ tryReadOptimistically() å¤±è´¥åç›´æ¥ä»å›é€€åˆ° pessimistic locking æ¨¡å¼ï¼Œä½¿ç”¨ lockShared() å’Œ unLockShared() å®Œæˆè¿™æ¬¡è¯»æ“ä½œã€‚</p><p>Hybrid-Lock å†åŠ ä¸Šåé¢æå‡ºçš„ ParkingLot çš„ lock contention å¤„ç†ç­–ç•¥å°±æ˜¯ç›®å‰ Umbra ä¸­ä½¿ç”¨çš„é”å®ç°ï¼Œæ›¿ä»£äº†ä¹‹å‰æåˆ°çš„ Versioned Latch æ–¹æ¡ˆã€‚ä¸‹é¢å°±æ˜¯ Hybrid Lock çš„ä¼ªä»£ç å®ç°ã€‚</p><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304052230691.png alt="Listing 2: Hybrid Locking"></p><h2 id=contention-handling>Contention Handling<a hidden class=anchor aria-hidden=true href=#contention-handling>#</a></h2><p>é”å†²çªæ˜¯å¾ˆéš¾é¿å…çš„ï¼Œæ¯”å¦‚åœ¨ write-heavy åœºæ™¯æ‰€æœ‰çº¿ç¨‹éƒ½ä½¿ç”¨ pessimistic locking æ—¶ï¼ŒHybrid Lock ä¸­çš„ RWMutex ä¸Šå°±å¯èƒ½å‘ç”Ÿé”å†²çªã€‚å¦‚ä½•é«˜æ•ˆå¤„ç†é”å†²çªï¼Œå¹¶ä¸”åœ¨çº¿ç¨‹ç­‰é”æœŸé—´èƒ½å¤Ÿè¯†åˆ«åˆ° query è¢« cancel åŠæ—¶åœæ­¢ query æ‰§è¡Œå‘¢ï¼Ÿ</p><p>è¿™ä¸ªç« èŠ‚ä½œè€…åˆ†æäº† Hybrid Lock å¯èƒ½çš„ RWMutex å®ç°ï¼Œæœ€ç»ˆé‡‡ç”¨äº† Parking Lot çš„æ–¹æ¡ˆã€‚</p><h3 id=busy-waitingspinning>Busy-Waiting/Spinning<a hidden class=anchor aria-hidden=true href=#busy-waitingspinning>#</a></h3><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304061335157.png alt="Figure 3: False-sharing"></p><p>Spinning æ˜¯ä¸€ç§å¸¸è§çš„å¤„ç†æ–¹å¼ï¼Œå’Œ <a href=https://en.wikipedia.org/wiki/Spinlock>Spinlock</a> ä¸€æ ·ã€‚Spinning çš„ä¸€äº›ç¼ºç‚¹ï¼š</p><ol><li>Spinning can lead to priority inversion, as spinning threads seem very busy to a scheduler they might receive higher priority than a thread that does useful work. Especially in the case of over-subscription, this can cause critical problems</li><li>Heavy spinning wastes resources and energy [6] and increases cache pollution, which is caused by additional bus traffic. ä½œè€…é€šè¿‡ cache line çš„ä¾‹å­è¯¦ç»†è§£é‡Šäº†è¿™ä¸ªé—®é¢˜ï¼šFollowing the MESI-protocol, every atomic write needs to invalidate all existing copies in other cores. Ideally, a core owns a cache line exclusively and does not need to send any invalidation messages. However, if other threads are spinning on the same lock, they constantly request this cache line, causing contention. The negative effects are worst when the waiting thread does write-for-ownership cycles, as those cause expensive invalida- tion messages. For this reason, a waiting thread should use the test-test-and-set pattern and only do the write-for-ownership cycle when it sees that the lock is available. In other words, it only reads the lock state in the busy loop to keep the lockâ€™s cache line in shared mode.</li><li>å’Œ lock å¤„äºåŒä¸€ cache line çš„æ•°æ®ä¹Ÿä¼šå—åˆ°å½±å“ï¼Œä¹Ÿå°±æ˜¯ false-sharing çš„é—®é¢˜ã€‚spinning can still lead to cache pollution when the protected data is on the same cache line as the lock itself (cf. Figure 3). By spinning on the lock the waiting thread ğ‘‡ğ‘¤ğ‘ğ‘–ğ‘¡ constantly loads the cache line in shared mode. Whenever the lock owning ğ‘‡hğ‘ğ‘ ğ¿ğ‘œğ‘ğ‘˜ updates the protected data, it must invalidate ğ‘‡ğ‘¤ğ‘ğ‘–ğ‘¡ â€™s copy of the cache line. Having to send these invalidation messages, slows down ğ‘‡hğ‘ğ‘ ğ¿ğ‘œğ‘ğ‘˜ and increases the time spent in the critical section.</li></ol><p>è™½ç„¶ç°æœ‰æ–¹æ¡ˆé€šè¿‡ backoff ç­–ç•¥å¯ä»¥ç¼“è§£ spinlock çš„è¿™äº›é—®é¢˜ï¼Œä½†è¿™äº›ç­–ç•¥æœ¬èº«ä¹Ÿä¸æ˜¯å¾ˆå®Œç¾ï¼š</p><blockquote><p>there exist several backoff strate- gies that add pause instructions to put the CPU into a lower power state, or call sched_yield to encourage the scheduler to switch to another thread. However, since the scheduler cannot guess when the thread wants to proceed, yielding is generally not recommended as its behavior is largely unpredictable [31].</p></blockquote><h3 id=local-spinning-using-queuing>Local Spinning using Queuing<a hidden class=anchor aria-hidden=true href=#local-spinning-using-queuing>#</a></h3><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304061340149.png alt="Figure 4: Queuing lock"></p><p>spinning å¸¦æ¥çš„ cache contention é—®é¢˜åœ¨ NUMA æ¶æ„ä¸Šä¼šæ›´ä¸¥é‡ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œä¸€äº› spinlock çš„å®ç°åª spin è¿™ä¸ª lock çš„ thread-local å‰¯æœ¬ï¼Œæ¯”å¦‚ MCS-lock æˆ–è€… Krieger et al. åœ¨ [13, 25] æå‡ºçš„ read-write mutexã€‚</p><p>è¿™ç§ lock çš„å·¥ä½œæ–¹å¼ï¼š</p><blockquote><p>When acquiring a lock, every thread creates a thread-local instance of the lock structure including its lock state and a next pointer to build a linked list of waiting threads.3 Then, it exchanges the next pointer of the global lock, making it point to its own local instance. If the previous next entry was nil, the lock acquisition was successful. Otherwise, if the entry already pointed to another instance, the thread enqueues itself in the wait- ing list by updating the next-pointer of the found instance (current tail) to itself.</p></blockquote><h3 id=ticket-spinlock>Ticket Spinlock<a hidden class=anchor aria-hidden=true href=#ticket-spinlock>#</a></h3><p>ticket spinlock æ˜¯å¦ä¸€ç§ spinlockï¼Œguarantees fairness without using queuesã€‚</p><p>å®ƒçš„å·¥ä½œæ–¹å¼ï¼š</p><blockquote><p>maintaining two counters: next-ticket and now-serving. A thread gets a ticket using an atomic fetch_and_add and waits until its ticket number matches that of now-serving.</p></blockquote><p>é™¤äº†èƒ½å¤Ÿä¿è¯ fairness ä»¥å¤–ï¼Œå®ƒè¿˜æœ‰å…¶ä»–ä¼˜ç‚¹ï¼š</p><blockquote><p>this also enables more precise backoff in case of contention by estimating the wait time. The wait time can be estimated by multiplying the position in the queue and the expected time spent in the critical section. Mellor-Crummey and Scott argue that it is best to use the minimal possible time for the critical section, as overshooting in backoff will delay all other threads in line due to the FIFO nature</p></blockquote><h3 id=kernel-supported-parkinglot>Kernel-Supported ParkingLot<a hidden class=anchor aria-hidden=true href=#kernel-supported-parkinglot>#</a></h3><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304061355223.png alt="Figure 5: Parking Lot"></p><p>ä¸Šé¢æåˆ°çš„ spinlock å§‹ç»ˆå­˜åœ¨ over-subscription æˆ–è€… waste of energy çš„é—®é¢˜ã€‚å› æ­¤å¾ˆå¤šåº“çš„é”å®ç°ï¼ˆæ¯”å¦‚ pthread mutexï¼‰éƒ½åŸºäº Linux å†…æ ¸æä¾›çš„ kernel-level locking æ¥ suspend å½“å‰è¿™ä¸ªçº¿ç¨‹ç›´åˆ°æ‹¿åˆ°è¿™ä¸ª lock ä¸ºæ­¢ã€‚</p><p>ä½†å†…æ ¸ä¸Šçš„ç³»ç»Ÿè°ƒç”¨å¼€é”€æ˜¯å¾ˆé«˜çš„ï¼Œæ‰€ä»¥ä¹Ÿæœ‰ä¸€äº›è‡ªé€‚åº”çš„é”å®ç°ï¼Œä»…é”å†²çªçš„æ—¶å€™æ‰è°ƒç”¨ kernel é˜»å¡å½“å‰çº¿ç¨‹ï¼Œæ¯”å¦‚ Linux æä¾›çš„ futexã€‚</p><p>åŸºäº futex çš„æ€è·¯ï¼ŒWebKit æå‡ºäº†ä¸€ä¸ªå« Parking Lot çš„è‡ªé€‚åº”é”ã€‚ä¹Ÿæ˜¯ Umbra ç›®å‰æ­£åœ¨ä½¿ç”¨çš„é”å®ç°ã€‚Parking Lot ç”¨ä¸€ä¸ªå…¨å±€å“ˆå¸Œè¡¨æ¥å­˜å‚¨ lock åˆ° wait queue çš„æ˜ å°„å…³ç³»ã€‚å’Œ Linux futex ä¸ä¸€æ ·ï¼Œè¿™ç§å®ç°æ–¹å¼æ›´åŠ é€šç”¨ï¼Œå¯ç§»æ¤æ€§å¼ºï¼Œä¸ä¾èµ–å…¶éæ ‡å‡†çš„æˆ–è€…ç‰¹å®šå¹³å°çš„ç³»ç»Ÿè°ƒç”¨ã€‚å®ƒä¹Ÿæ›´åŠ çµæ´»ï¼Œæ¯”å¦‚åœ¨ Parking çš„æ—¶å€™å¯ä»¥æ‰§è¡ŒæŸä¸ª callback å‡½æ•°ã€‚Umbra åˆ©ç”¨è¿™ä¸ªç‰¹æ€§åœ¨é”ç­‰å¾…æ—¶æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦è¢«å–æ¶ˆï¼ŒPage æ˜¯å¦å·²ç»è¢«ç¼“å­˜æ›¿æ¢ç­‰ã€‚</p><p>ä¸Šå›¾æè¿°äº† Umbra ä¸­å®ç°çš„ Parking Lot é”ã€‚å½“çº¿ç¨‹è·å–é”åä¼šå°† lock bit (L) è®¾ç½®ä¸º 1ã€‚å½“å¦ä¸€ä¸ªçº¿ç¨‹å†æ¬¡è·å–é”æ—¶ï¼Œå®ƒä¼šåœ¨ parking lot ä¸­ç­‰å¾…ã€‚æ­¤æ—¶å®ƒä¼šæŠŠé”çš„ wait bit (W) è®¾ç½®ä¸º 1 è¡¨ç¤ºæœ‰äººæ­£åœ¨ç­‰é”ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªé”çš„åœ°å€åœ¨å“ˆå¸Œè¡¨ä¸­æ‰¾åˆ°è¯¥é”å¯¹åº”çš„ parking spaceã€‚å¦‚æœä»æ—§æ»¡è¶³ç”¨æˆ·è‡ªå®šä¹‰çš„ wait conditionï¼Œè¯¥çº¿ç¨‹å¼€å§‹ç­‰å¾…è¿™ä¸ª condition variableã€‚å½“ç¬¬ 1 ä¸ªçº¿ç¨‹é‡Šæ”¾é”åï¼Œå®ƒå‘ç° wait bit (W) ä¸º 1 çŸ¥é“æœ‰å…¶ä»–çº¿ç¨‹æ­£åœ¨ç­‰é”ï¼Œå®ƒä¼šæ‰¾åˆ°è¿™ä¸ªé”å¯¹åº”çš„ parking spaceï¼Œå°†æ‰€æœ‰ç­‰å¾…çš„çº¿ç¨‹éƒ½å”¤é†’ã€‚ä¸ºäº†é¿å… parking space çš„ data race é—®é¢˜ï¼Œæ¯ä¸ª parking space éƒ½æœ‰ä¸€ä¸ª mutex æ¥ä¿æŠ¤ã€‚</p><p>å…³äº lock bit å’Œ wait bitï¼Œä½œè€…åœ¨è®ºæ–‡çš„ 2.3 å°ç»“ä»‹ç»å®Œ Hybrid Lock åæœ‰ä¸ªè¡¥å……è¯´æ˜ï¼Œæ”¾åˆ°è¿™é‡Œæˆ‘ä»¬äº†è§£åˆ° parking lot åå°±æ¯”è¾ƒå®¹æ˜“ç†è§£äº†ï¼š</p><ul><li>wait bitï¼šencode åœ¨ Hybrid-Lock çš„ RWMutex ä¸Šï¼Œç”¨æ¥è¡¨ç¤ºæœ‰å…¶ä»–çº¿ç¨‹ç­‰é”</li><li>lock bitï¼šencode åœ¨ Hybrid-Lock çš„ version ä¸Šï¼Œæ£€æµ‹åˆ°æœ‰é”åå½“å‰çº¿ç¨‹éœ€è¦è°ƒç”¨ä¸‹é¢ä¼ªä»£ç ä¸­çš„ <code>park()</code> å‡½æ•°è¿›å…¥ parking çŠ¶æ€ï¼Œç›´åˆ°è¢« condition variable å”¤é†’ã€‚</li></ul><p>Parking lot æœ¬è´¨ä¸Šå°±æ˜¯ä¸ªå›ºå®š 512 æ§½ä½çš„å“ˆå¸Œè¡¨ï¼Œå› ä¸ºå†²çªçš„é”æ•°é‡æœ€å¤šä¸ä¼šè¶…è¿‡ä½¿ç”¨çš„çº¿ç¨‹æ•°ï¼Œæ‰€ä»¥ 512 ä¸ªæ§½ä½å°±è¶³å¤Ÿç”¨äº†ã€‚é‡‡ç”¨æ‹‰é“¾æ³•è§£å†³å“ˆå¸Œå†²çªã€‚</p><p>å½“æ‰§è¡Œç”¨æˆ· query çš„çº¿ç¨‹åœ¨ parking space ä¸­ç­‰å¾…æ—¶ï¼Œæ¯ 10ms ä¼šè¢«å”¤é†’æ£€æŸ¥å½“å‰ query æ˜¯å¦è¢«å–æ¶ˆäº†ï¼Œä»¥ä¾¿åœæ­¢ç­‰å¾…åŠæ—¶ç»“æŸå½“å‰ query çš„æ‰§è¡Œã€‚</p><p>ä¸‹é¢æ˜¯ parking lot çš„ä¼ªä»£ç ã€‚è™½ç„¶éå¸¸ç®€å•ç›´æ¥ï¼Œä½†ä½¿ç”¨éœ€è¦ç‰¹åˆ«å°å¿ƒã€‚éœ€è¦ç¡®ä¿é€ æˆçº¿ç¨‹ç­‰å¾…çš„ä¿¡æ¯ä¸ä¼šä¸¢å¤±å¯¼è‡´çº¿ç¨‹æ— é™æœŸçš„ç­‰å¾…ä¸‹å»ï¼Œä»»ä½•ä¿®æ”¹è¿™äº›æ•°æ®çš„çº¿ç¨‹éƒ½éœ€è¦æ£€æŸ¥é”çš„ wait bitï¼Œåœ¨å¿…è¦æ—¶å”¤é†’æ‰€æœ‰ç­‰å¾…çš„çº¿ç¨‹ã€‚ä½œè€…è¿™é‡Œæ²¡ä¸¾ä¾‹å­ï¼Œæˆ‘èƒ½æƒ³åˆ°çš„ä¸€ä¸ªåœºæ™¯æ˜¯ B Tree Node è¢«ç¼“å­˜æ›¿æ¢çš„åœºæ™¯ã€‚</p><p><img src=https://raw.githubusercontent.com/zz-jason/blog-images/master/images/202304061357401.png alt="Listing 3: Parking Lot Implementation"></p><p>è®ºæ–‡åˆ°è¿™ï¼ˆç¬¬ 5 é¡µï¼‰æ ¸å¿ƒå†…å®¹å°±ç»“æŸäº†ï¼Œåé¢èŠ±äº†å¤§é‡çš„ç¯‡å¹…ä»‹ç»å’Œå±•ç¤ºä½œè€…çš„æµ‹è¯•ç»“æœã€‚</p><h2 id=evaluation>Evaluation<a hidden class=anchor aria-hidden=true href=#evaluation>#</a></h2><h3 id=tpc-c-and-tpc-h>TPC-C and TPC-H<a hidden class=anchor aria-hidden=true href=#tpc-c-and-tpc-h>#</a></h3><h3 id=lock-granularity>Lock Granularity<a hidden class=anchor aria-hidden=true href=#lock-granularity>#</a></h3><h3 id=space-consumption>Space Consumption<a hidden class=anchor aria-hidden=true href=#space-consumption>#</a></h3><h3 id=efficiency-of-lock-acquisition>Efficiency of Lock Acquisition<a hidden class=anchor aria-hidden=true href=#efficiency-of-lock-acquisition>#</a></h3><h3 id=contention-handling-strategies>Contention Handling Strategies<a hidden class=anchor aria-hidden=true href=#contention-handling-strategies>#</a></h3><h2 id=related-work>RELATED WORK<a hidden class=anchor aria-hidden=true href=#related-work>#</a></h2><h2 id=conclusion>CONCLUSION<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2></div><footer class=post-footer><nav class=paginav><a class=prev href=https://zz-jason.github.io/posts/vldb-2022-memory-opotimized-mvcc/><span class=title>Â« Prev Page</span><br><span>[VLDB 2022] Memory-Optimized Multi-Version Concurrency Control for Disk-Based Database Systems</span></a>
<a class=next href=https://zz-jason.github.io/posts/icde-2018-leanstore/><span class=title>Next Page Â»</span><br><span>[ICDE 2018] LeanStore: In-Memory Data Management Beyond Main Memory</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share [VLDB 2023] Scalable and Robust Latches for Database Systems on twitter" href="https://twitter.com/intent/tweet/?text=%5bVLDB%202023%5d%20Scalable%20and%20Robust%20Latches%20for%20Database%20Systems&url=https%3a%2f%2fzz-jason.github.io%2fposts%2fvldb-2023-scalable-and-robust-latches%2f&hashtags="><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [VLDB 2023] Scalable and Robust Latches for Database Systems on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fzz-jason.github.io%2fposts%2fvldb-2023-scalable-and-robust-latches%2f&title=%5bVLDB%202023%5d%20Scalable%20and%20Robust%20Latches%20for%20Database%20Systems&summary=%5bVLDB%202023%5d%20Scalable%20and%20Robust%20Latches%20for%20Database%20Systems&source=https%3a%2f%2fzz-jason.github.io%2fposts%2fvldb-2023-scalable-and-robust-latches%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [VLDB 2023] Scalable and Robust Latches for Database Systems on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fzz-jason.github.io%2fposts%2fvldb-2023-scalable-and-robust-latches%2f&title=%5bVLDB%202023%5d%20Scalable%20and%20Robust%20Latches%20for%20Database%20Systems"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zm-119.474 108.193c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zm-160.386-29.702c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [VLDB 2023] Scalable and Robust Latches for Database Systems on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fzz-jason.github.io%2fposts%2fvldb-2023-scalable-and-robust-latches%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978v-192.915h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [VLDB 2023] Scalable and Robust Latches for Database Systems on whatsapp" href="https://api.whatsapp.com/send?text=%5bVLDB%202023%5d%20Scalable%20and%20Robust%20Latches%20for%20Database%20Systems%20-%20https%3a%2f%2fzz-jason.github.io%2fposts%2fvldb-2023-scalable-and-robust-latches%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23-13.314-11.876-22.304-26.542-24.916-31.026s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share [VLDB 2023] Scalable and Robust Latches for Database Systems on telegram" href="https://telegram.me/share/url?text=%5bVLDB%202023%5d%20Scalable%20and%20Robust%20Latches%20for%20Database%20Systems&url=https%3a%2f%2fzz-jason.github.io%2fposts%2fvldb-2023-scalable-and-robust-latches%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47A3.38 3.38.0 0126.49 29.86zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><script src=https://utteranc.es/client.js repo=zz-jason/zz-jason.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></article></main><footer class=footer><span>&copy; 2023 <a href=https://zz-jason.github.io/>Jian Zhang</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);if(!window.matchMedia('(prefers-reduced-motion: reduce)').matches){document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});}else{document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();}
if(id==="top"){history.replaceState(null,null," ");}else{history.pushState(null,null,`#${id}`);}});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script></body></html>